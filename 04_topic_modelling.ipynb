{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 14 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "# Utilities\n",
    "from joblib import Parallel, delayed\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress bar\")\n",
    "import gc\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "# Import time packages \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Visualization Tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Packages needed for text pre-processing:\n",
    "import nltk \n",
    "import spacy \n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Doc\n",
    "from spacy.language import Language\n",
    "import re\n",
    "import contractions\n",
    "import emoji\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Deep Learning Models \n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "# Sentiment Packages\n",
    "from textblob import TextBlob\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import torch\n",
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import search_folder\n",
    "current_dir = os.getcwd()\n",
    "thesis_folder_path = current_dir.replace(\"thesis_code\", \"\")\n",
    "twitter_data_path = search_folder(thesis_folder_path,\"twitter_data\")\n",
    "eikon_data_path = search_folder(thesis_folder_path,\"eikon_news\")\n",
    "stock_data_path = search_folder(thesis_folder_path,\"stock_prices\")\n",
    "modelling_data_path = search_folder(thesis_folder_path,\"modelling_data\")\n",
    "google_trending_path = search_folder(thesis_folder_path,\"google_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving sentiment on raw text \n",
    "twitter_senti_raw_df = pd.read_csv(twitter_data_path +\"/twitter_senti_raw_df.csv\")\n",
    "twitter_senti_raw_df[\"datetime\"] = pd.to_datetime(twitter_senti_raw_df[\"datetime\"])\n",
    "twitter_senti_raw_df =twitter_senti_raw_df.sort_values(by = \"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving sentiment on cleaned text\n",
    "twitter_senti_df = pd.read_csv(twitter_data_path +\"/twitter_senti_df.csv\")\n",
    "twitter_senti_df[\"datetime\"] = pd.to_datetime(twitter_senti_df[\"datetime\"])\n",
    "twitter_senti_df =twitter_senti_df.sort_values(by = \"datetime\")\n",
    "twitter_senti_df = twitter_senti_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving Sentiment on Eikon Raw News \n",
    "eikon_senti_df = pd.read_csv(eikon_data_path +\"/raw_eikon_senti_df.csv\")\n",
    "eikon_senti_df[\"datetime\"] = pd.to_datetime(eikon_senti_df[\"datetime\"])\n",
    "eikon_senti_df =eikon_senti_df.sort_values(by = \"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(cleaned_tweets_df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(twitter_senti_raw_df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(twitter_senti_df\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(cleaned_tweets_df.shape)\n",
    "print(twitter_senti_raw_df.shape)\n",
    "print(twitter_senti_df.shape)\n",
    "print(eikon_senti_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "Tuesday      387865\n",
       "Wednesday    385878\n",
       "Thursday     376579\n",
       "Friday       346848\n",
       "Monday       343058\n",
       "Saturday     166083\n",
       "Sunday       151677\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cleaned_tweets_df.datetime.dt.day_name().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "Wednesday    9026\n",
       "Thursday     8827\n",
       "Tuesday      8635\n",
       "Friday       7746\n",
       "Monday       7096\n",
       "Saturday     1983\n",
       "Sunday       1110\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eikon_senti_df.datetime.dt.day_name().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress bar: 100%|██████████| 2157990/2157990 [00:08<00:00, 242785.99it/s]\n",
      "progress bar: 100%|██████████| 2157988/2157988 [00:08<00:00, 242929.80it/s]\n",
      "progress bar: 100%|██████████| 44423/44423 [00:00<00:00, 233269.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tweets on Saturday and Sunday are moved to Monday in order to not losse any relevance\n",
    "from utils import fix_dates\n",
    "twitter_senti_raw_df[\"datetime\"] = twitter_senti_raw_df[\"datetime\"].progress_apply(lambda x: fix_dates(x))\n",
    "twitter_senti_df[\"datetime\"] = twitter_senti_df[\"datetime\"].progress_apply(lambda x: fix_dates(x))\n",
    "eikon_senti_df[\"datetime\"] = eikon_senti_df[\"datetime\"].progress_apply(lambda x: fix_dates(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
