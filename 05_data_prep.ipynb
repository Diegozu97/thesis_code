{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"663fe6f441c44f9880b9f428081a10ff","deepnote_cell_type":"code"},"source":["# Preparing data for Modelling"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import utils\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns \n","import matplotlib.cm as cm\n","plt.style.use('ggplot')\n","\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n","from sklearn.base import clone\n","\n","import seaborn as sns\n","\n","import quantstats as qs\n","import os \n","# pd.set_option('display.max_rows', None)\n","import os \n","\n","# To automatically load changes in different files \n","%load_ext autoreload\n","%autoreload 2\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","# Applying Settings to Viaualization Tools \n","plt.rcParams['font.size'] = 13\n","plt.rcParams['axes.titlesize'] = 20\n","plt.rcParams['axes.labelsize'] = 16\n","plt.rcParams['xtick.labelsize'] = 14\n","plt.rcParams['ytick.labelsize'] = 14\n","# Set color palette to blue shades\n","sns.set_palette([\"#003366\", \"#6699CC\", \"#99CCFF\", \"#99CCFF\"])\n","sns.set_palette([\"#002855\", \"#3E7EAA\", \"#82B5D8\", \"#B3D9F2\"])\n","plt.rcParams['font.family'] = 'Times New Roman'\n","sns.set_style(\"darkgrid\")\n","\n","from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, mean_absolute_percentage_error\n","import statsmodels.api as sm\n","\n","import xgboost\n","from xgboost import XGBRegressor\n","# create an xgboost regression model\n","\n","import tqdm \n","from tqdm import tqdm "]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from utils import search_folder\n","current_dir = os.getcwd()\n","thesis_folder_path = current_dir.replace(\"thesis_code\", \"\")\n","twitter_data_path = search_folder(thesis_folder_path,\"twitter_data\")\n","eikon_data_path = search_folder(thesis_folder_path,\"eikon_news\")\n","stock_data_path = search_folder(thesis_folder_path,\"stock_prices\")\n","modelling_data_path = search_folder(thesis_folder_path,\"modelling_data\")\n","google_trending_path = search_folder(thesis_folder_path,\"google_search\")\n","results_folder = search_folder(thesis_folder_path,\"results_output\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def read_modelling(path, name):\n","    df = pd.read_csv(path+name)\n","    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n","    df = df.sort_values(by = \"datetime\", ascending = True)\n","    df = df.reset_index(drop = True)\n","    return df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Stock Data "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>close</th>\n","      <th>net</th>\n","      <th>ret</th>\n","      <th>open</th>\n","      <th>low</th>\n","      <th>high</th>\n","      <th>volume</th>\n","      <th>turnover_usd</th>\n","      <th>flow</th>\n","      <th>company</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-03</td>\n","      <td>14.465986</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>14.323986</td>\n","      <td>14.063986</td>\n","      <td>14.688652</td>\n","      <td>8.884890e+07</td>\n","      <td>1.283684e+09</td>\n","      <td>0.000000e+00</td>\n","      <td>tesla</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-03</td>\n","      <td>29.037500</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>28.950000</td>\n","      <td>28.690000</td>\n","      <td>29.082500</td>\n","      <td>1.151275e+08</td>\n","      <td>3.327549e+09</td>\n","      <td>0.000000e+00</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-04</td>\n","      <td>29.005000</td>\n","      <td>-0.0325</td>\n","      <td>-0.001119</td>\n","      <td>28.962500</td>\n","      <td>28.937500</td>\n","      <td>29.127500</td>\n","      <td>8.447246e+07</td>\n","      <td>2.452484e+09</td>\n","      <td>-2.452484e+09</td>\n","      <td>apple</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime      close     net       ret       open        low       high  \\\n","0 2017-01-03  14.465986     NaN       NaN  14.323986  14.063986  14.688652   \n","1 2017-01-03  29.037500     NaN       NaN  28.950000  28.690000  29.082500   \n","2 2017-01-04  29.005000 -0.0325 -0.001119  28.962500  28.937500  29.127500   \n","\n","         volume  turnover_usd          flow company  \n","0  8.884890e+07  1.283684e+09  0.000000e+00   tesla  \n","1  1.151275e+08  3.327549e+09  0.000000e+00   apple  \n","2  8.447246e+07  2.452484e+09 -2.452484e+09   apple  "]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["stock_data_df = read_modelling(modelling_data_path, \"/all_stocks_returns_df.csv\")\n","stock_data_df.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Fama French Model Features "]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>beta_mktrf</th>\n","      <th>beta_smb</th>\n","      <th>beta_hml</th>\n","      <th>beta_rmw</th>\n","      <th>beta_cma</th>\n","      <th>idvar_ff5</th>\n","      <th>company</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-03</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>moderna</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-03</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>tesla</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-03</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>apple</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  beta_mktrf  beta_smb  beta_hml  beta_rmw  beta_cma  idvar_ff5  \\\n","0 2017-01-03         NaN       NaN       NaN       NaN       NaN        NaN   \n","1 2017-01-03         NaN       NaN       NaN       NaN       NaN        NaN   \n","2 2017-01-03         NaN       NaN       NaN       NaN       NaN        NaN   \n","\n","   company  \n","0  moderna  \n","1    tesla  \n","2    apple  "]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["fama_french_feat_df = read_modelling(modelling_data_path, \"/fama_variables_companies.csv\")\n","fama_french_feat_df.head(3)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# # joining stock data with fama french factors\n","# master_table = pd.merge(stock_data_df, fama_french_feat_df, how = \"left\", left_on=[\"datetime\", \"company\"], right_on = [\"datetime\", \"company\"])\n","# master_table = master_table.drop_duplicates()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Sentiment Model Features "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>company</th>\n","      <th>daytweets</th>\n","      <th>textblob_tw_sw</th>\n","      <th>vader_tw_sw</th>\n","      <th>finbert_tw_sw</th>\n","      <th>textblob_senti_sw</th>\n","      <th>vader_sw</th>\n","      <th>finbert_senti_sw</th>\n","      <th>textblob_senti_tw</th>\n","      <th>vader_senti_tw</th>\n","      <th>finbert_senti_tw</th>\n","      <th>news_count</th>\n","      <th>eik_textblob_senti_sw</th>\n","      <th>eik_finbert_senti_sw</th>\n","      <th>eik_vader_senti_sw</th>\n","      <th>textblob_eik_twi_senti</th>\n","      <th>finbert_eik_twi_senti</th>\n","      <th>vader_eik_twi_senti</th>\n","      <th>datetime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-02</td>\n","      <td>apple</td>\n","      <td>195364</td>\n","      <td>108.654740</td>\n","      <td>145.5335</td>\n","      <td>-35.0</td>\n","      <td>50.796503</td>\n","      <td>476</td>\n","      <td>-22.0</td>\n","      <td>57.858238</td>\n","      <td>83.1307</td>\n","      <td>-13.0</td>\n","      <td>16.0</td>\n","      <td>0.107143</td>\n","      <td>-6.0</td>\n","      <td>-0.2248</td>\n","      <td>0.139497</td>\n","      <td>0.330854</td>\n","      <td>0.247211</td>\n","      <td>2017-01-02 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-02</td>\n","      <td>google</td>\n","      <td>32400</td>\n","      <td>27.841547</td>\n","      <td>4.7608</td>\n","      <td>-50.0</td>\n","      <td>11.939170</td>\n","      <td>203</td>\n","      <td>-23.0</td>\n","      <td>15.902377</td>\n","      <td>7.2756</td>\n","      <td>-27.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.117251</td>\n","      <td>0.340631</td>\n","      <td>0.228702</td>\n","      <td>2017-01-02 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-02</td>\n","      <td>tesla</td>\n","      <td>27556</td>\n","      <td>69.120491</td>\n","      <td>56.5365</td>\n","      <td>15.0</td>\n","      <td>25.982624</td>\n","      <td>181</td>\n","      <td>0.0</td>\n","      <td>43.137866</td>\n","      <td>33.4803</td>\n","      <td>15.0</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>-1.0</td>\n","      <td>0.0000</td>\n","      <td>0.127801</td>\n","      <td>0.342587</td>\n","      <td>0.236034</td>\n","      <td>2017-01-02 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2017-01-03</td>\n","      <td>apple</td>\n","      <td>187489</td>\n","      <td>100.070978</td>\n","      <td>73.2125</td>\n","      <td>-24.0</td>\n","      <td>49.393965</td>\n","      <td>462</td>\n","      <td>-12.0</td>\n","      <td>50.677013</td>\n","      <td>32.8160</td>\n","      <td>-12.0</td>\n","      <td>4.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.135711</td>\n","      <td>0.342123</td>\n","      <td>0.238395</td>\n","      <td>2017-01-03 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2017-01-03</td>\n","      <td>google</td>\n","      <td>15876</td>\n","      <td>19.047536</td>\n","      <td>36.4611</td>\n","      <td>-18.0</td>\n","      <td>9.819791</td>\n","      <td>135</td>\n","      <td>-9.0</td>\n","      <td>9.227745</td>\n","      <td>16.5585</td>\n","      <td>-9.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.115003</td>\n","      <td>0.342467</td>\n","      <td>0.233191</td>\n","      <td>2017-01-03 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6210</th>\n","      <td>2023-04-13</td>\n","      <td>moderna</td>\n","      <td>25</td>\n","      <td>4.696667</td>\n","      <td>2.5965</td>\n","      <td>5.0</td>\n","      <td>2.348333</td>\n","      <td>5</td>\n","      <td>3.0</td>\n","      <td>2.348333</td>\n","      <td>1.5842</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.111336</td>\n","      <td>0.343787</td>\n","      <td>0.228395</td>\n","      <td>2023-04-13 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6213</th>\n","      <td>2023-04-14</td>\n","      <td>google</td>\n","      <td>961</td>\n","      <td>6.778229</td>\n","      <td>8.8280</td>\n","      <td>-10.0</td>\n","      <td>2.089114</td>\n","      <td>34</td>\n","      <td>-4.0</td>\n","      <td>4.689114</td>\n","      <td>5.1707</td>\n","      <td>-6.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.111868</td>\n","      <td>0.342926</td>\n","      <td>0.229278</td>\n","      <td>2023-04-14 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6214</th>\n","      <td>2023-04-14</td>\n","      <td>moderna</td>\n","      <td>289</td>\n","      <td>3.375763</td>\n","      <td>4.5592</td>\n","      <td>16.0</td>\n","      <td>1.622256</td>\n","      <td>18</td>\n","      <td>8.0</td>\n","      <td>1.753506</td>\n","      <td>2.6954</td>\n","      <td>8.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.110998</td>\n","      <td>0.344418</td>\n","      <td>0.228673</td>\n","      <td>2023-04-14 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6212</th>\n","      <td>2023-04-14</td>\n","      <td>apple</td>\n","      <td>13924</td>\n","      <td>42.478908</td>\n","      <td>52.1386</td>\n","      <td>8.0</td>\n","      <td>23.767439</td>\n","      <td>126</td>\n","      <td>1.0</td>\n","      <td>18.711469</td>\n","      <td>24.3339</td>\n","      <td>7.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.120992</td>\n","      <td>0.343959</td>\n","      <td>0.235411</td>\n","      <td>2023-04-14 00:00:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>6215</th>\n","      <td>2023-04-14</td>\n","      <td>tesla</td>\n","      <td>164836</td>\n","      <td>95.025373</td>\n","      <td>91.1145</td>\n","      <td>-111.0</td>\n","      <td>48.136581</td>\n","      <td>444</td>\n","      <td>-67.0</td>\n","      <td>46.888793</td>\n","      <td>41.9997</td>\n","      <td>-44.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0000</td>\n","      <td>0.134422</td>\n","      <td>0.337132</td>\n","      <td>0.240931</td>\n","      <td>2023-04-14 00:00:00+00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6216 rows × 20 columns</p>\n","</div>"],"text/plain":["            date  company  daytweets  textblob_tw_sw  vader_tw_sw  \\\n","0     2017-01-02    apple     195364      108.654740     145.5335   \n","1     2017-01-02   google      32400       27.841547       4.7608   \n","2     2017-01-02    tesla      27556       69.120491      56.5365   \n","3     2017-01-03    apple     187489      100.070978      73.2125   \n","4     2017-01-03   google      15876       19.047536      36.4611   \n","...          ...      ...        ...             ...          ...   \n","6210  2023-04-13  moderna         25        4.696667       2.5965   \n","6213  2023-04-14   google        961        6.778229       8.8280   \n","6214  2023-04-14  moderna        289        3.375763       4.5592   \n","6212  2023-04-14    apple      13924       42.478908      52.1386   \n","6215  2023-04-14    tesla     164836       95.025373      91.1145   \n","\n","      finbert_tw_sw  textblob_senti_sw  vader_sw  finbert_senti_sw  \\\n","0             -35.0          50.796503       476             -22.0   \n","1             -50.0          11.939170       203             -23.0   \n","2              15.0          25.982624       181               0.0   \n","3             -24.0          49.393965       462             -12.0   \n","4             -18.0           9.819791       135              -9.0   \n","...             ...                ...       ...               ...   \n","6210            5.0           2.348333         5               3.0   \n","6213          -10.0           2.089114        34              -4.0   \n","6214           16.0           1.622256        18               8.0   \n","6212            8.0          23.767439       126               1.0   \n","6215         -111.0          48.136581       444             -67.0   \n","\n","      textblob_senti_tw  vader_senti_tw  finbert_senti_tw  news_count  \\\n","0             57.858238         83.1307             -13.0        16.0   \n","1             15.902377          7.2756             -27.0         0.0   \n","2             43.137866         33.4803              15.0         1.0   \n","3             50.677013         32.8160             -12.0         4.0   \n","4              9.227745         16.5585              -9.0         0.0   \n","...                 ...             ...               ...         ...   \n","6210           2.348333          1.5842               2.0         0.0   \n","6213           4.689114          5.1707              -6.0         0.0   \n","6214           1.753506          2.6954               8.0         0.0   \n","6212          18.711469         24.3339               7.0         0.0   \n","6215          46.888793         41.9997             -44.0         0.0   \n","\n","      eik_textblob_senti_sw  eik_finbert_senti_sw  eik_vader_senti_sw  \\\n","0                  0.107143                  -6.0             -0.2248   \n","1                  0.000000                   0.0              0.0000   \n","2                  0.000000                  -1.0              0.0000   \n","3                  0.000000                   0.0              0.0000   \n","4                  0.000000                   0.0              0.0000   \n","...                     ...                   ...                 ...   \n","6210               0.000000                   0.0              0.0000   \n","6213               0.000000                   0.0              0.0000   \n","6214               0.000000                   0.0              0.0000   \n","6212               0.000000                   0.0              0.0000   \n","6215               0.000000                   0.0              0.0000   \n","\n","      textblob_eik_twi_senti  finbert_eik_twi_senti  vader_eik_twi_senti  \\\n","0                   0.139497               0.330854             0.247211   \n","1                   0.117251               0.340631             0.228702   \n","2                   0.127801               0.342587             0.236034   \n","3                   0.135711               0.342123             0.238395   \n","4                   0.115003               0.342467             0.233191   \n","...                      ...                    ...                  ...   \n","6210                0.111336               0.343787             0.228395   \n","6213                0.111868               0.342926             0.229278   \n","6214                0.110998               0.344418             0.228673   \n","6212                0.120992               0.343959             0.235411   \n","6215                0.134422               0.337132             0.240931   \n","\n","                      datetime  \n","0    2017-01-02 00:00:00+00:00  \n","1    2017-01-02 00:00:00+00:00  \n","2    2017-01-02 00:00:00+00:00  \n","3    2017-01-03 00:00:00+00:00  \n","4    2017-01-03 00:00:00+00:00  \n","...                        ...  \n","6210 2023-04-13 00:00:00+00:00  \n","6213 2023-04-14 00:00:00+00:00  \n","6214 2023-04-14 00:00:00+00:00  \n","6212 2023-04-14 00:00:00+00:00  \n","6215 2023-04-14 00:00:00+00:00  \n","\n","[6216 rows x 20 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["sentiment_df = pd.read_csv(modelling_data_path + \"/master_table_news_sentiment.csv\")\n","sentiment_df[\"datetime\"] = pd.to_datetime(sentiment_df[\"date\"], utc = True)\n","sentiment_df = sentiment_df.sort_values(by = \"datetime\")\n","sentiment_df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Topic Modelling Features"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Google Trending News for Companies"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>interest</th>\n","      <th>company</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-04-08</td>\n","      <td>31</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-04-15</td>\n","      <td>1</td>\n","      <td>moderna</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-04-15</td>\n","      <td>33</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-04-15</td>\n","      <td>18</td>\n","      <td>tesla</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018-04-22</td>\n","      <td>31</td>\n","      <td>apple</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  interest  company\n","0 2018-04-08        31    apple\n","1 2018-04-15         1  moderna\n","2 2018-04-15        33    apple\n","3 2018-04-15        18    tesla\n","4 2018-04-22        31    apple"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["comp_google_search_df = read_modelling(modelling_data_path, \"/google_searches_companies.csv\")\n","comp_google_search_df.head()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>interest</th>\n","      <th>company</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-04-09</td>\n","      <td>31</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-04-16</td>\n","      <td>1</td>\n","      <td>moderna</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-04-16</td>\n","      <td>33</td>\n","      <td>apple</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2018-04-16</td>\n","      <td>18</td>\n","      <td>tesla</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2018-04-23</td>\n","      <td>31</td>\n","      <td>apple</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  interest  company\n","0 2018-04-09        31    apple\n","1 2018-04-16         1  moderna\n","2 2018-04-16        33    apple\n","3 2018-04-16        18    tesla\n","4 2018-04-23        31    apple"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["from utils import fix_dates\n","comp_google_search_df[\"datetime\"] = comp_google_search_df[\"datetime\"].apply(lambda x: fix_dates(x))\n","comp_google_search_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Google Trending News for Macro-News"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>pandemic_mentions</th>\n","      <th>inflation_mentions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-04-08</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-04-15</td>\n","      <td>1</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-04-22</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  pandemic_mentions  inflation_mentions\n","0 2018-04-08                  1                  17\n","1 2018-04-15                  1                  16\n","2 2018-04-22                  1                  17"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["makro_google_search_df = read_modelling(modelling_data_path, \"/google_macro_searches.csv\")\n","makro_google_search_df.head(3)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>pandemic_mentions</th>\n","      <th>inflation_mentions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018-04-09</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018-04-16</td>\n","      <td>1</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018-04-23</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  pandemic_mentions  inflation_mentions\n","0 2018-04-09                  1                  17\n","1 2018-04-16                  1                  16\n","2 2018-04-23                  1                  17"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["makro_google_search_df[\"datetime\"] = makro_google_search_df[\"datetime\"].apply(lambda x: fix_dates(x))\n","makro_google_search_df.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Macro-Economic Data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>datetime</th>\n","      <th>euro_doll_bid</th>\n","      <th>euro_doll_ask</th>\n","      <th>eur_doll_high</th>\n","      <th>eur_doll_low</th>\n","      <th>eur_doll_open</th>\n","      <th>refresh_rate</th>\n","      <th>euro_doll_bidnet</th>\n","      <th>nasdaq_close</th>\n","      <th>nasdaqd_net</th>\n","      <th>nasdaqd_ret</th>\n","      <th>nasdaq_open</th>\n","      <th>nasdaq_low</th>\n","      <th>nasdaq_high</th>\n","      <th>nasdaq_volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2017-01-03</td>\n","      <td>1.0404</td>\n","      <td>1.0408</td>\n","      <td>1.0490</td>\n","      <td>1.0339</td>\n","      <td>1.0453</td>\n","      <td>74707.0</td>\n","      <td>-0.0053</td>\n","      <td>4911.334</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4900.854</td>\n","      <td>4884.522</td>\n","      <td>4928.490</td>\n","      <td>152438794</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2017-01-04</td>\n","      <td>1.0486</td>\n","      <td>1.0490</td>\n","      <td>1.0499</td>\n","      <td>1.0387</td>\n","      <td>1.0403</td>\n","      <td>91660.0</td>\n","      <td>0.0082</td>\n","      <td>4937.205</td>\n","      <td>25.871</td>\n","      <td>0.005268</td>\n","      <td>4920.792</td>\n","      <td>4919.803</td>\n","      <td>4944.745</td>\n","      <td>141126335</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2017-01-05</td>\n","      <td>1.0603</td>\n","      <td>1.0611</td>\n","      <td>1.0615</td>\n","      <td>1.0478</td>\n","      <td>1.0489</td>\n","      <td>103626.0</td>\n","      <td>0.0117</td>\n","      <td>4964.953</td>\n","      <td>27.748</td>\n","      <td>0.005620</td>\n","      <td>4936.355</td>\n","      <td>4935.343</td>\n","      <td>4967.901</td>\n","      <td>140485654</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    datetime  euro_doll_bid  euro_doll_ask  eur_doll_high  eur_doll_low  \\\n","0 2017-01-03         1.0404         1.0408         1.0490        1.0339   \n","1 2017-01-04         1.0486         1.0490         1.0499        1.0387   \n","2 2017-01-05         1.0603         1.0611         1.0615        1.0478   \n","\n","   eur_doll_open  refresh_rate  euro_doll_bidnet  nasdaq_close  nasdaqd_net  \\\n","0         1.0453       74707.0           -0.0053      4911.334          NaN   \n","1         1.0403       91660.0            0.0082      4937.205       25.871   \n","2         1.0489      103626.0            0.0117      4964.953       27.748   \n","\n","   nasdaqd_ret  nasdaq_open  nasdaq_low  nasdaq_high  nasdaq_volume  \n","0          NaN     4900.854    4884.522     4928.490      152438794  \n","1     0.005268     4920.792    4919.803     4944.745      141126335  \n","2     0.005620     4936.355    4935.343     4967.901      140485654  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["macro_data_df = read_modelling(modelling_data_path, \"/macro_data.csv\")\n","macro_data_df.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","## Features Table"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# joining stock data with fama french factors\n","master_table = pd.merge(stock_data_df, fama_french_feat_df, how = \"left\", left_on=[\"datetime\", \"company\"], right_on = [\"datetime\", \"company\"])\n","master_table = master_table.drop_duplicates()\n","\n","#  joining master table with macro data from Eikon \n","master_table = pd.merge(master_table, macro_data_df, how = \"left\", left_on=[\"datetime\"], right_on = [\"datetime\"])\n","master_table = master_table.drop_duplicates()\n","\n","# Joining master table with makro data from google search \n","master_table = pd.merge(master_table, makro_google_search_df, how = \"left\", left_on=[\"datetime\"], right_on = [\"datetime\"])\n","master_table = master_table.drop_duplicates()\n","\n","# Joining master table with makro data from google search \n","master_table = pd.merge(master_table, comp_google_search_df, how = \"left\", left_on=[\"datetime\", \"company\"], right_on = [\"datetime\", \"company\"])\n","master_table = master_table.drop_duplicates()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["--- \n","### 7 - Additional Features: (Technical Analysis, Sentiment, Price patterns, etc.)"]},{"cell_type":"code","execution_count":358,"metadata":{},"outputs":[],"source":["def prepare_df(df, col_to_pred : str, Ssenti_vars: list, lag):\n","    \n","    window = 10\n","    df[\"sma\"] = df[\"close\"].rolling(window=window, min_periods=1).mean()\n","    sma = df[\"close\"].rolling(window=window, min_periods=1).mean()\n","    \n","    # Calculate RSI (Relative Strength Index)\n","    diff = df[\"close\"].diff()\n","    up, down = diff.copy(), diff.copy()\n","    up[up < 0] = 0\n","    down[down > 0] = 0\n","    avg_gain = up.rolling(window=window, min_periods=1).mean()\n","    avg_loss = abs(down.rolling(window=window, min_periods=1).mean())\n","    rs = avg_gain / avg_loss\n","    rsi = 100 - (100 / (1 + rs))\n","    df[\"rsi\"] = rsi\n","\n","    # Calculate MACD (Moving Average Convergence Divergence)\n","    ema_12 = df[\"close\"].ewm(span=12, adjust=False).mean()\n","    ema_26 = df[\"close\"].ewm(span=26, adjust=False).mean()\n","    macd = ema_12 - ema_26\n","    df[\"macd\"] = macd\n","    signal = macd.ewm(span=9, adjust=False).mean()\n","    df[\"signal\"] = signal\n","\n","    # Calculate Bollinger Bands\n","    rolling_std = df[\"close\"].rolling(window=window, min_periods=1).std()\n","    upper_band = sma + 2 * rolling_std\n","    lower_band = sma - 2 * rolling_std\n","    \n","    df[\"rolling_std\"] = rolling_std\n","    \n","    df[\"upper_bollinger\"] = df[\"close\"] > upper_band\n","    df[\"lower_bollinger\"] = df[\"close\"] < lower_band\n","    \n","    \n","    df[\"upper_bollinger\"] = df[\"upper_bollinger\"].apply(lambda x : 1 if x == True else 0)\n","    df[\"lower_bollinger\"] = df[\"lower_bollinger\"].apply(lambda x : 1 if x == True else 0)\n","\n","    # Computing 1 day forward target prediction  \n","    target_var = \"ft_target\"\n","    df[\"ft_target\"] = df[col_to_pred].shift(-lag)\n","    \n","    for lag in range(0,11): \n","        df[\"lag_\"+ str(lag)] = df[col_to_pred].shift(lag)\n","         \n","    df['mean2w'] = df[\"lag_0\"].rolling(window=10).mean()\n","    df['std2w'] = df[\"lag_0\"].rolling(window=10).std()\n","    df['std1w'] = df[\"lag_0\"].rolling(window=5).std()\n","    \n","    for senti_var in Ssenti_vars: \n","        for lag in range(1, 380, 10): \n","            df[\"rolled_\"+ senti_var + \"_\" +str(lag)] = df[senti_var].rolling(window = lag, min_periods=0).sum()\n","            \n","    for senti_var in Ssenti_vars: \n","        for lag in range(2, 20, 1): \n","            df[\"rolled_\"+ senti_var + \"_\" +str(lag)] = df[senti_var].rolling(window = lag, min_periods=0).sum()\n","     \n","    df = df.drop(columns = [col_to_pred])\n","    \n","    df = df.drop_duplicates()\n","    \n","    df.fillna(0.0)\n","    \n","    return df"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","### Selecting Company and Adding Sentiment Variables"]},{"cell_type":"code","execution_count":381,"metadata":{},"outputs":[],"source":["company = \"tesla\"\n","comp_pred_df = master_table[master_table[\"company\"] == company]\n","comp_pred_df.loc[:, \"interest\"] = comp_pred_df[\"interest\"].ffill().fillna(0.0) # modify the original DataFrame using .loc\n","comp_pred_df.loc[:, \"rolling_interest\"] = comp_pred_df[\"interest\"].rolling(3).mean().ffill().fillna(0.0)\n","comp_pred_df.loc[:, \"pandemic_mentions\"] = comp_pred_df[\"pandemic_mentions\"].ffill().fillna(0.0)\n","comp_pred_df.loc[:, \"inflation_mentions\"] = comp_pred_df[\"inflation_mentions\"].ffill().fillna(0.0)\n","\n","# Selecting company\n","single_sentiment_df = sentiment_df[sentiment_df[\"company\"] == company]\n","single_sentiment_df = single_sentiment_df.sort_values(by = \"datetime\")\n","\n","comp_pred_df[\"datetime\"] = pd.to_datetime(comp_pred_df[\"datetime\"], utc = True)\n","\n","# Merging Sentimnent with company data \n","comp_pred_df_senti = pd.merge(comp_pred_df, single_sentiment_df, how = \"left\", on = [\"datetime\"])\n","\n","senti_vars = list(sentiment_df.columns[3:-1])\n","senti_vars.remove(\"news_count\")\n","\n","# Compute technical labels and fill NaN values with 0.0\n","comp_pred_df_senti['vol'] = comp_pred_df_senti[\"ret\"].rolling(window=252).std() * np.sqrt(252)\n","comp_pred_final_df = prepare_df(comp_pred_df_senti, \"close\", senti_vars, 1)\n","comp_pred_final_df = comp_pred_final_df.fillna(0.0)\n","\n","# Define lists of column names\n","macro_vars = [ 'open', 'low', 'high', 'volume', 'euro_doll_bid', 'euro_doll_ask', 'eur_doll_high', 'eur_doll_low', 'eur_doll_open', 'refresh_rate', \n","              'euro_doll_bidnet', 'nasdaq_close', 'nasdaqd_net', 'nasdaqd_ret', 'nasdaq_open', 'nasdaq_low', 'nasdaq_high', 'nasdaq_volume'\n","              ]\n","\n","google_vars = [\"pandemic_mentions\", \"inflation_mentions\", 'interest', 'rolling_interest']\n","\n","lagged_vars = ['lag_0', 'lag_1', 'lag_2', 'lag_3', 'lag_4',    'lag_5', 'lag_6', 'lag_7', 'lag_8', 'lag_9', \"lag_10\"]\n","\n","techni_vars = ['mean2w', 'std2w', 'std1w']\n","\n","fama_vars = ['beta_mktrf', 'beta_smb', 'beta_hml', 'beta_rmw', 'beta_cma']\n","\n","technical_vars = [\"sma\", \"rsi\", \"macd\", \"signal\", \"rolling_std\", \"upper_bollinger\", \"lower_bollinger\"]\n","\n","Csenti_vars = list(comp_pred_final_df.columns[75:])\n","Csenti_vars += [\"daytweets\", \"news_count\"]\n","date = [\"datetime\"]\n","ft_target = [\"ft_target\"] # \n","\n","#Csenti_vars.sort(reverse=True)"]},{"cell_type":"code","execution_count":382,"metadata":{},"outputs":[],"source":["from class_backtester import Backtester as bk \n","#model_config = {'model': {'alpha_estimation_method':'Lasso', \"alpha\": 0.1}}\n","model_config = {'model': {'alpha_estimation_method':'xgboost'}}"]},{"cell_type":"code","execution_count":383,"metadata":{},"outputs":[],"source":["all_feat = None\n","all_feat = date + macro_vars + google_vars + lagged_vars + techni_vars + fama_vars + ft_target  + technical_vars + [\"rolled_finbert_eik_twi_senti_281\", \"rolled_eik_vader_senti_sw_141\"]           \n","comp_pred_df_senti = comp_pred_df_senti[all_feat]\n","comp_pred_df_senti = comp_pred_df_senti[comp_pred_df_senti[\"datetime\"] <= \"2023-02-15 00:00:00+00:00\"]\n","comp_pred_df_senti.dropna(subset=[\"ft_target\"], inplace=True)\n","comp_pred_df_senti = comp_pred_df_senti.fillna(0.0)\n","modelling_ft = all_feat.copy()\n","modelling_ft.remove(\"datetime\")\n","modelling_ft.remove(\"ft_target\")"]},{"cell_type":"code","execution_count":384,"metadata":{},"outputs":[],"source":["def retrieve_results(df, target_column, model_config, senti_var):\n","    \n","    company = \"moderna\"\n","    target = target_column\n","    variables = \"all\"\n","    sentiment = senti_var\n","    model = \"xgboost\"\n","    comments = \"permutations\"\n","\n","    counter = 0\n","    backtester = bk(df = df,\n","                    modeling_features = modelling_ft,\n","                    rolling_frw = '1D',\n","                    look_back_prm = 252, \n","                    configurations= model_config, \n","                    col_to_pred = target_column)\n","\n","    backtester.run_backtest()\n","    track_results = {}\n","    resutls_df = backtester.dict_all_predictions[\"model\"][[\"datetime\", \"ft_target\",\"ft_target_pred\"]]\n","    resutls_df['y_test'] = (resutls_df['ft_target'] > resutls_df['ft_target'].shift()).astype(int)\n","    resutls_df['y_test'] = resutls_df['y_test'].fillna(0)\n","    resutls_df['y_pred'] = (resutls_df['ft_target_pred'] > resutls_df['ft_target_pred'].shift()).astype(int)\n","    resutls_df['y_pred'] = resutls_df['y_pred'].fillna(0)\n","    resutls_df = resutls_df.set_index(\"datetime\")\n","    track_results[\"trial_\"+str(counter)] = {}\n","    track_results[\"trial_\"+str(counter)][\"company\"] = company\n","    track_results[\"trial_\"+str(counter)][\"target\"] = target\n","    track_results[\"trial_\"+str(counter)][\"variables\"] = variables\n","    track_results[\"trial_\"+str(counter)][\"sentiment\"] = sentiment\n","    track_results[\"trial_\"+str(counter)][\"model\"] = model\n","    track_results[\"trial_\"+str(counter)][\"comments\"] = comments\n","    track_results[\"trial_\"+str(counter)][\"precision\"] = precision_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","    track_results[\"trial_\"+str(counter)][\"recall\"] = recall_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","    track_results[\"trial_\"+str(counter)][\"accuracy\"] = accuracy_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","    track_results[\"trial_\"+str(counter)][\"f1_score\"] = f1_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","    track_results[\"trial_\"+str(counter)][\"mae\"] = round(mean_absolute_percentage_error(resutls_df.iloc[:,:2][\"ft_target\"], resutls_df.iloc[:,:2][\"ft_target_pred\"]),5)*100\n","    track_results[\"trial_\"+str(counter)][\"datetime\"] = list(resutls_df[\"ft_target\"].index)\n","    track_results[\"trial_\"+str(counter)][\"y_test\"] = list(resutls_df[\"ft_target\"].values)\n","    track_results[\"trial_\"+str(counter)][\"y_pred\"] = list(resutls_df[\"ft_target_pred\"].values)\n","    results_df = pd.DataFrame.from_dict(track_results, orient='index')\n","    \n","    return results_df"]},{"cell_type":"code","execution_count":385,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1981/1981 [02:23<00:00, 13.76it/s]\n"]}],"source":["test = retrieve_results(comp_pred_df_senti, \"ft_target\", model_config, \"rolled_finbert_eik_twi_senti_281\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>company</th>\n","      <th>target</th>\n","      <th>variables</th>\n","      <th>sentiment</th>\n","      <th>model</th>\n","      <th>comments</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>accuracy</th>\n","      <th>f1_score</th>\n","      <th>mae</th>\n","      <th>datetime</th>\n","      <th>y_test</th>\n","      <th>y_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>trial_0</th>\n","      <td>moderna</td>\n","      <td>ft_target</td>\n","      <td>all</td>\n","      <td>rolled_finbert_eik_twi_senti_281</td>\n","      <td>xgboost</td>\n","      <td>permutations</td>\n","      <td>0.497167</td>\n","      <td>0.494366</td>\n","      <td>0.476923</td>\n","      <td>0.495763</td>\n","      <td>3.643</td>\n","      <td>[2017-09-12 00:00:00+00:00, 2017-09-13 00:00:0...</td>\n","      <td>[24.415309, 25.175975, 25.320641, 25.666641, 2...</td>\n","      <td>[23.70515, 24.171894, 24.526588, 25.336428, 25...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         company     target variables                         sentiment  \\\n","trial_0  moderna  ft_target       all  rolled_finbert_eik_twi_senti_281   \n","\n","           model      comments  precision    recall  accuracy  f1_score  \\\n","trial_0  xgboost  permutations   0.497167  0.494366  0.476923  0.495763   \n","\n","           mae                                           datetime  \\\n","trial_0  3.643  [2017-09-12 00:00:00+00:00, 2017-09-13 00:00:0...   \n","\n","                                                    y_test  \\\n","trial_0  [24.415309, 25.175975, 25.320641, 25.666641, 2...   \n","\n","                                                    y_pred  \n","trial_0  [23.70515, 24.171894, 24.526588, 25.336428, 25...  "]},"execution_count":377,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for senti_var in tqdm(range(len(Csenti_vars))):\n","        try:\n","                all_feat = None \n","                modelling_ft = None\n","                all_feat = date + macro_vars + google_vars + lagged_vars + techni_vars + fama_vars + ft_target  + technical_vars + [Csenti_vars[senti_var]]\n","                modelling_ft =  all_feat\n","                modelling_ft =  modelling_ft.remove(date[0])\n","                modelling_ft =  modelling_ft.remove(ft_target[0])\n","                \n","                comp_pred_final = comp_pred_final_df[all_feat]\n","                comp_pred_final = comp_pred_final.iloc[:-1,:]\n","                comp_pred_final = comp_pred_final[comp_pred_final[\"datetime\"] <= \"2023-02-15 00:00:00+00:00\"]\n","                all_results_df = pd.read_csv(results_folder + \"/moderna_results_summary.csv\", index_col =[0])\n","                all_results_df = all_results_df.drop_duplicates()\n","\n","                company = \"moderna\"\n","                target = \"close\"\n","                variables = \"all\"\n","                sentiment = Csenti_vars[senti_var]\n","                model = \"xgboost\"\n","                comments = \"permutations\"\n","\n","                counter = len(all_results_df)\n","                backtester = bk(df = comp_pred_final,\n","                                modeling_features = modelling_ft,\n","                                rolling_frw = '1D',\n","                                look_back_prm = 252, \n","                                configurations= model_config, \n","                                col_to_pred = 'ft_target')\n","\n","                backtester.run_backtest()\n","                track_results = {}\n","                resutls_df = backtester.dict_all_predictions[\"model\"][[\"datetime\", \"ft_target\",\"ft_target_pred\"]]\n","                resutls_df['y_test'] = (resutls_df['ft_target'] > resutls_df['ft_target'].shift()).astype(int)\n","                resutls_df['y_test'] = resutls_df['y_test'].fillna(0)\n","                resutls_df['y_pred'] = (resutls_df['ft_target_pred'] > resutls_df['ft_target_pred'].shift()).astype(int)\n","                resutls_df['y_pred'] = resutls_df['y_pred'].fillna(0)\n","                resutls_df = resutls_df.set_index(\"datetime\")\n","                track_results[\"trial_\"+str(counter)] = {}\n","                track_results[\"trial_\"+str(counter)][\"company\"] = company\n","                track_results[\"trial_\"+str(counter)][\"target\"] = target\n","                track_results[\"trial_\"+str(counter)][\"variables\"] = variables\n","                track_results[\"trial_\"+str(counter)][\"sentiment\"] = sentiment\n","                track_results[\"trial_\"+str(counter)][\"model\"] = model\n","                track_results[\"trial_\"+str(counter)][\"comments\"] = comments\n","                track_results[\"trial_\"+str(counter)][\"precision\"] = precision_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","                track_results[\"trial_\"+str(counter)][\"recall\"] = recall_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","                track_results[\"trial_\"+str(counter)][\"accuracy\"] = accuracy_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","                track_results[\"trial_\"+str(counter)][\"f1_score\"] = f1_score(resutls_df[\"y_test\"], resutls_df[\"y_pred\"])\n","                track_results[\"trial_\"+str(counter)][\"mae\"] = round(mean_absolute_percentage_error(resutls_df.iloc[:,:2][\"ft_target\"], resutls_df.iloc[:,:2][\"ft_target_pred\"]),5)*100\n","                track_results[\"trial_\"+str(counter)][\"datetime\"] = list(resutls_df[\"ft_target\"].index)\n","                track_results[\"trial_\"+str(counter)][\"y_test\"] = list(resutls_df[\"ft_target\"].values)\n","                track_results[\"trial_\"+str(counter)][\"y_pred\"] = list(resutls_df[\"ft_target_pred\"].values)\n","                results_df = pd.DataFrame.from_dict(track_results, orient='index')\n","                all_results_df = pd.concat([all_results_df, results_df])\n","                all_results_df.to_csv(results_folder + \"/moderna_results_summary.csv\")\n","        except: \n","                continue"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","### Statistically Significant Variables "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import statsmodels.api as sm\n","modelling_ft_2 = modelling_ft[:50]\n","X = comp_pred_final[modelling_ft_2]\n","y = comp_pred_final[\"ft_target\"]\n","model = sm.OLS(y, sm.add_constant(X)).fit()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["no_sentiment = resutls_df.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["no_sentiment[\"noSenti_resi\"] = abs(no_sentiment[\"ft_target\"] - no_sentiment[\"ft_target_pred\"])\n","no_sentiment[\"noSenti_resi\"] = no_sentiment[\"noSenti_resi\"].rolling(31).mean()\n","resutls_df[\"Senti_resi\"] = abs(resutls_df[\"ft_target\"] - resutls_df[\"ft_target_pred\"])\n","resutls_df[\"Senti_resi\"] = resutls_df[\"Senti_resi\"].rolling(31).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,5))\n","plt.plot(no_sentiment.index, no_sentiment.ft_target)\n","plt.plot(no_sentiment.index, no_sentiment.ft_target_pred, color = \"red\")\n","plt.plot(resutls_df.index, resutls_df.ft_target_pred)\n","plt.legend([\"target\", \"no_sentiment\", \"sentiment\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,5))\n","plt.plot(no_sentiment.index, no_sentiment.noSenti_resi)\n","plt.plot(resutls_df.index, resutls_df.Senti_resi, color = \"green\")\n","plt.legend([\"no_sentiment\", \"sentiment\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,5))\n","plt.plot(no_sentiment.index, no_sentiment.ft_target)\n","plt.plot(no_sentiment.index, no_sentiment.ft_target_pred, color = \"red\")\n","plt.plot(resutls_df.index, resutls_df.ft_target_pred)\n","plt.legend([\"target\", \"no_sentiment\", \"sentiment\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["no_sentiment[\"noSenti_resi\"] = abs(no_sentiment[\"ft_target\"] - no_sentiment[\"ft_target_pred\"])\n","no_sentiment[\"noSenti_resi\"] = no_sentiment[\"noSenti_resi\"].rolling(365).mean()\n","resutls_df[\"Senti_resi\"] = abs(resutls_df[\"ft_target\"] - resutls_df[\"ft_target_pred\"])\n","resutls_df[\"Senti_resi\"] = resutls_df[\"Senti_resi\"].rolling(365).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(20,5))\n","plt.plot(no_sentiment.index, no_sentiment.noSenti_resi)\n","plt.plot(resutls_df.index, resutls_df.Senti_resi, color = \"green\")\n","plt.legend([\"no_sentiment\", \"sentiment\"])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"c554fd7e06a94110b37fedc9a665a024","kernelspec":{"display_name":"test","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
